{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0f6cdc19f49f27d304540c94e517753cec0fc989b1dfe618742c310b8a679cd44",
   "display_name": "Python 3.9.2 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tasca 4: PrÃ ctica amb programaciÃ³ numÃ¨rica\n",
    "\n",
    "## DescripciÃ³ :\n",
    "Familiaritza't amb la ProgramaciÃ³ NumÃ¨rica a travÃ©s de la llibreria NumPy.\n",
    "\n",
    "## Nivell 1\n",
    "\n",
    "- Exercici 1 :\n",
    "Crea una funciÃ³ que donat un Array dâ€™una dimensiÃ³, et faci un resum estadÃ­stic bÃ sic de les dades. Si detecta que lâ€™array tÃ© mÃ©s dâ€™una dimensiÃ³, ha de mostrar un missatge dâ€™error."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NumPy Array:\n[0.10802149 0.78514351 0.69576968 0.07319701 0.89950807 0.32112165\n 0.54377807 0.3258196  0.37898464 0.71400288]\nOne dimensional Matrix with random elements: \n [0.10802149 0.78514351 0.69576968 0.07319701 0.89950807 0.32112165\n 0.54377807 0.3258196  0.37898464 0.71400288]\nNumPy Array:\n[0.10802149 0.78514351 0.69576968 0.07319701 0.89950807 0.32112165\n 0.54377807 0.3258196  0.37898464 0.71400288]\nReshaped Matrix with the shape (5, 2) : \n[[0.10802149 0.32112165]\n [0.78514351 0.54377807]\n [0.69576968 0.3258196 ]\n [0.07319701 0.37898464]\n [0.89950807 0.71400288]]\n\nError the dimension is 2 > 1\n\nStatistical summary : \n\nThe average of the array is : 0.48453465843084814\nNumpy library :  0.4845346584308482\nUser function :  0.4845346584308482\n\nThe maximum occurring value of the array is : 0.10802149316691756\n\nThe median of the array is : 0.46138135046519213\nNumpy library :  0.46138135046519213\n\nThe lower median of the array is : 0.3789846355987082\n\nThe higher median of the array is : 0.543778065331676\n\nThe 50th percentile of the array is : 0.04377806533167605\n\nPopulation Variance of the array is : 0.07373502061516828\nNumpy library :  0.07373502061516826\nSample Variance of the array is : 0.0819278006835203\n\nPopulation Standard Deviation of the array is : 0.2715419315965184\nNumpy library :  0.27154193159651835\nSample Standard Deviation of the array is : 0.2862303280288801\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# importing statistics to handle statistical operations\n",
    "import statistics\n",
    "from statistics import variance\n",
    "\n",
    "def random_matrix(func):\n",
    "    # added arguments inside the wrapper, if function takes\n",
    "    # any arguments, can be added like this.\n",
    "    def wrapper(*args, **kwargs):\n",
    "  \n",
    "        # getting the returned value\n",
    "        array = func(*args, **kwargs)\n",
    "  \n",
    "        print(f'NumPy Array:\\n{array}')\n",
    "        # returning the value to the original frame\n",
    "        return array\n",
    "    return wrapper\n",
    "\n",
    "@random_matrix\n",
    "def create_array(*args, **kwargs):\n",
    "    # Generates a random vector with a given length\n",
    "    return np.random.rand(*args, **kwargs)\n",
    "\n",
    "def reshape_array(arr, *shape, order = 'C'):\n",
    "#    Parameters :\n",
    "#       array : [array_like]Input array\n",
    "#       shape : [int or tuples of int] e.g. if we are aranging an array with 10\n",
    "#       elements then shaping it like numpy.reshape(4, 8) is wrong; we can order:\n",
    "#       [C-contiguous, F-contiguous, A-contiguous; optional]         \n",
    "#       C-contiguous order in memory(last index varies the fastest)\n",
    "#       C order means that operating row-rise on the array will be slightly quicker\n",
    "#       FORTRAN-contiguous order in memory (first index varies the fastest).\n",
    "#       F order means that column-wise operations will be faster. \n",
    "#       â€˜Aâ€™ means to read / write the elements in Fortran-like index order if,\n",
    "#       array is Fortran contiguous in memory, C-like order otherwise\n",
    "    #print(arr); print('unpackage tuple: ', *shape); print(order)\n",
    "    newarr = arr.reshape(*shape, order = order )\n",
    "    return newarr\n",
    "    '''\n",
    "    ndim = len(shape)\n",
    "    #print('Number of dims', ndim)\n",
    "    if ndim == 2:\n",
    "        n1, n2 = [int(x) for x in shape]\n",
    "        newarr = arr.reshape(n1, n2, order = order )\n",
    "    elif ndim == 3:\n",
    "        n1, n2, n3 = [int(x) for x in shape]\n",
    "        newarr = arr.reshape(n1, n2, n3, order = order)\n",
    "    elif ndim == 4:\n",
    "        n1, n2, n3, n4 = [int(x) for x in shape]\n",
    "        newarr = arr.reshape(n1, n2, n3, n4, order = order)\n",
    "    elif ndim == 5:\n",
    "        n1, n2, n3, n4, n5 = [int(x) for x in shape]\n",
    "        newarr = arr.reshape(n1, n2, n3, n4, n5, order = order)\n",
    "    elif ndim == 6:\n",
    "        n1, n2, n3, n4, n5, n6 = [int(x) for x in shape]\n",
    "        newarr = arr.reshape(n1, n2, n3, n4, n5, n6, order = order)\n",
    "    elif ndim == 7:\n",
    "        n1, n2, n3, n4, n5, n6, n7 = [int(x) for x in shape]\n",
    "        newarr = arr.reshape(n1, n2, n3, n4, n5, n6, n7, order = order)\n",
    "    else:\n",
    "        print('Out of range : Number of dims {0} is > 7 '.format(ndim))\n",
    "    return newarr\n",
    "    '''\n",
    "def smart_divide(func):\n",
    "    def inner(a, b):\n",
    "        #print(\"Dividing : \", a, \" and \", b)\n",
    "        if b == 0:\n",
    "            print(\"Whoops! cannot divide\")\n",
    "            return\n",
    "        return func(a, b)\n",
    "    return inner\n",
    "\n",
    "@smart_divide\n",
    "def divide(a, b):\n",
    "    return float(a/b)\n",
    "\n",
    "arr = create_array(10)\n",
    "print('One dimensional Matrix with random elements: \\n', arr)\n",
    "print(f'NumPy Array:\\n{arr}')\n",
    "\n",
    "shape = (5, 2)\n",
    "newarr = reshape_array(arr, *shape, order = 'F')\n",
    "print('Reshaped Matrix with the shape {0} : \\n{1}\\n'. format(shape, newarr))\n",
    "\n",
    "# Taking a view makes it possible to modify the shape without modifying the initial object.\n",
    "#arr_view = arr.view()\n",
    "#print('The original Matrix : \\n', arr)\n",
    "#print('The original Matrix : \\n', arr.base)\n",
    "\n",
    "def dim_control(arr):\n",
    "    #print('shape of array :', newarr.shape)\n",
    "    dim = len(arr.shape) \n",
    "    if dim > 1:\n",
    "        print('Error the dimension is {0} > 1'.format(dim))\n",
    "        return arr.reshape(-1)\n",
    "\n",
    "newarr = dim_control(newarr)\n",
    "#print(f'NumPy Array:\\n{newarr}')\n",
    "\n",
    "#Important Average and measure of central location functions :\n",
    "\n",
    "#1. mean() :- This function returns the mean or average of the data passed in its arguments. If passed argument is empty, StatisticsError is raised.\n",
    "\n",
    "def mean_stats(arr):\n",
    "    len = arr.size\n",
    "    if len == 0:\n",
    "        print('StatisticsError')\n",
    "    else:\n",
    "        sum = arr.sum()\n",
    "        #sum = np.sum(arr)\n",
    "        #print(sum, len)\n",
    "    return divide(sum, len)\n",
    "\n",
    "# Converting one-dimensional NumPy Array to List\n",
    "list1 = newarr.tolist()\n",
    "\n",
    "print('\\nStatistical summary : ')\n",
    "\n",
    "# using mean() to calculate average of list elements\n",
    "print (\"\\nThe average of the array is : % s\" %(statistics.mean(newarr)))\n",
    "print ('Numpy library : ', np.mean(newarr))\n",
    "print ('User function : ', mean_stats(newarr))\n",
    "\n",
    "#2. mode() :- This function returns the number with maximum number of occurrences. If passed argument is empty, StatisticsError is raised.\n",
    "# using mode() to print maximum occurring of list elements\n",
    "print (\"\\nThe maximum occurring value of the array is : % s\" %(statistics.mode(newarr)))\n",
    "\n",
    "#3. median() :- This function is used to calculate the median, i.e middle element of data. If passed argument is empty, StatisticsError is raised.\n",
    "# using median() to print median of list elements\n",
    "print (\"\\nThe median of the array is : % s\" %(statistics.median(newarr)))\n",
    "print ('Numpy library : ', np.median(newarr))\n",
    "\n",
    "#4. median_low() :- This function returns the median of data in case of odd number of elements, but in case of even number of elements, returns the lower of two middle elements. If passed argument is empty, StatisticsError is raised.\n",
    "# using median_low() to print low median of list elements\n",
    "print (\"\\nThe lower median of the array is : % s\" %(statistics.median_low(newarr)))\n",
    "\n",
    "#5. median_high() :- This function returns the median of data in case of odd number of elements, but in case of even number of elements, returns the higher of two middle elements. If passed argument is empty, StatisticsError is raised.\n",
    "# using median_high() to print high median of list elements\n",
    "print (\"\\nThe higher median of the array is : % s\" %(statistics.median_high(newarr)))\n",
    "\n",
    "#6. median_grouped() :- This function is used to compute group median, i.e 50th percentile of the data. If passed argument is empty, StatisticsError is raised.\n",
    "# using median_grouped() to calculate 50th percentile\n",
    "print (\"\\nThe 50th percentile of the array is : % s\" %(statistics.median_grouped(newarr)))\n",
    "\n",
    "#7. Variance : is the squared deviation of a variable from its mean. Basically, it measures the spread of random data in a set from its mean or median value. A low value for variance indicates that the data are clustered together and are not spread apart widely, whereas a high value would indicate that the data in the given set are much more spread apart from the average value.\n",
    "# Population variance of data.\n",
    "# Function will automatically calculate it's mean and set it as xbar\n",
    "print(\"\\nPopulation Variance of the array is : % s\" %(statistics.pvariance(newarr)))\n",
    "print ('Numpy library : ', np.var(newarr))\n",
    "# Sample variance of data.\n",
    "print(\"Sample Variance of the array is : % s\" %(statistics.variance(newarr)))\n",
    "\n",
    "#8. Standard Deviation is a measure of spread in Statistics. It is used to quantify the measure of spread, variation of a set of data values. It is very much similar to variance, gives the measure of deviation whereas variance provides the squared value.\n",
    "# Population standard deviation of data\n",
    "# Prints standard deviation xbar is set to default value of 1\n",
    "print (\"\\nPopulation Standard Deviation of the array is : % s\" %(statistics.pstdev(newarr)))\n",
    "print ('Numpy library : ', np.std(newarr))\n",
    "# Sample standard deviation of data\n",
    "print (\"Sample Standard Deviation of the array is : % s\" %(statistics.stdev(newarr)))"
   ]
  },
  {
   "source": [
    "\n",
    "## Statistical formulas for sample data :\n",
    "\n",
    "$\\text{Mean :}$\n",
    "\n",
    "$$\\overline{x} = \\frac {\\sum x}{n}$$\n",
    "\n",
    "$\\text{Sample Variance :}$\n",
    "\n",
    "$$s^{2} = \\frac{{\\displaystyle \\sum_{i=1}^{n} \\left(x_{i}-\\overline{x}\\right)^{2}}}{n-1}$$\n",
    "\n",
    "$\\text{Sample Standard Deviation :}$\n",
    "\n",
    "$$s = \\sqrt{\\text{Variance}} =\\sqrt{\\frac{{\\displaystyle \\sum\\nolimits_{i=1}^{n} \\left(x_{i}-\\overline{x}\\right)^{2}}}{n-1}}$$\n",
    "<!--- \n",
    "<span class=\"comment\">\n",
    "[//]: # (Comment) $$s=\\sqrt{\\frac{{\\displaystyle \\sum_{i=1}^{N} \\left(x_{i}-\\overline{x}\\right)^{2}}}{N-1}}$$\n",
    "</span>\n",
    "-->\n",
    "\n",
    "$\\text{where:}$\n",
    "\n",
    "$x_{1}, x_{2}, x_{3}...x_{n} \\text{ are observed values in sample data, } \\overline {x} \\text{ is the mean value of observations and } \\mathit{n} \\text{ is the number of observations.}$\n",
    "\n",
    "Generally, when you have only a fraction of the population, i.e., a sample, you should divide by $n-1$. There is a good reason for doing so, we know that the sample variance, which multiplies the mean squared deviation of the sample mean by $(n-1)/n$, is an unbiased estimator of the population variance.\n",
    "\n",
    "<img src=\"Variance_SampleSize.png\"  alt=\"Variance Graph\" style = \"position:relative; left:250px; top:0px;\" width=\"30%\" height=\"30%\" >\n",
    "\n",
    "**Note:**, in this figure the variance should be close to 1. Look how much it varies with sample size when you use $N$ to estimate the variance. (this is the \"bias\" referred to elswhere)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xs = norm.rvs(scale = 2, size = 100)\n",
    "#xs = np.arange(-4, 4, 0.001)\n",
    "#xs = [1, 6, 5, 2, 5, 4, 5, 8, 9, 4, 3, 10, 6]\n",
    "#print(xs)\n",
    "\n",
    "v = np.var(xs)                                  # Variance\n",
    "m = np.mean(xs)                                 # Mean\n",
    "s = np.std(xs)                                  # Standard Deviation\n",
    "\n",
    "#ax = fig.add_subplot(111)\n",
    "ax.hist(xs, bins=10, alpha=0.5, density=True)                           # Plot Histogram\n",
    "x = np.linspace(-10, 10, 100)                   # Distribution curve scale limits and size of dx   \n",
    "ax.plot(x, norm.pdf(x, scale = s), label='stdv=%.1f' % s)\n",
    "#p = norm.pdf(x, scale = 2)    # Scale plot distribution curve\n",
    "#ax.plot(x, p, 'r-', lw = 2)                                            # Plot Distribution Curve\n",
    "\n",
    "ax.set_ylim(0, 0.25)                                                     # range\n",
    "ax.axhline(y = 0.2, xmax = 0.5, color = 'r')                            # horizontal line\n",
    "ax.axvline(x = 0, ymax = 0.8, color = 'r', alpha = 0.5)                 # vertical line\n",
    "xplot = ax.plot([0], [0.2], marker='o', markersize = 5, color = \"red\")  # coordinate point\n",
    "#ax.set_yticks([])                                                      # remove y axis label\n",
    "#ax.set_xticks([])                                                      # remove x axis label\n",
    "ax.set_title(f'Normal Distribution: mean={m:.2f}, var={v:.2f}, std={s:.2f}')\n",
    "ax.legend(loc='best', frameon=True)\n",
    "ax.set_xlabel('x', fontsize = 20)                                       # set x label\n",
    "ax.set_ylabel('pdf(x)', fontsize = 20, rotation = 90)                   # set y label\n",
    "ax.xaxis.set_label_coords(0.5, -0.06)                                   # x label coordinate\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)                                    # y label coordinate\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Introduction\n",
    "\n",
    "<a href=\"https://www.wikiwand.com/en/Normal_distribution\">Normal distributions</a> are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known. The Normal distribution is a continuous theoretical probability distribution. In this article, I am going to explore the Normal distribution using Jupyter.\n",
    "\n",
    "Let's import all the necessary libraries.\n",
    "```\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "## Normal Distribution Probability Density Function\n",
    "\n",
    "### Probability density function (PDF) of the normal distribution is :\n",
    "\n",
    "$$f(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}} \\text{, where } x\\in \\mathbb{R}$$\n",
    "\n",
    "The random variable $X$ described by the **PDF** is a normal variable that follows a normal distribution with mean $\\mu$ and variance $\\sigma^2$.\n",
    "\n",
    "Normal distribution notation is :\n",
    "\n",
    "$$X \\sim N(\\mu,\\sigma^2)$$\n",
    "\n",
    "The area under the curve equals 1.\n",
    "\n",
    "$$\\int \\limits _{-\\infty} ^{+\\infty}f(x)dx=1$$\n",
    "\n",
    "### ``norm.pdf value``\n",
    "``norm.pdf`` retuns a pdf value. The following is the pdf value when $x=1$, $\\mu=0$, $\\sigma=1$.\n",
    "\n",
    "<a href=\"https://nbviewer.jupyter.org/github/shinokada/python-for-ib-diploma-mathematics/blob/master/Normal_distribution.ipynb#norm.pdf-value\" >Jupyter nbviewer</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/exploring-normal-distribution-with-jupyter-notebook-3645ec2d83f8\" >Exploring Normal Distribution With Jupyter Notebook</a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.pdf(x=1.0, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x= np.arange(-4,4,0.001)\n",
    "ax.plot(x, norm.pdf(x))\n",
    "ax.set_ylim(0,0.45) # range\n",
    "ax.axhline(y=0.24,xmax=0.61,color='r') # horizontal line\n",
    "ax.axvline(x=1, ymax=0.53, color='r',alpha=0.5) # vertical line\n",
    "xplot = ax.plot([1], [0.24], marker='o', markersize=15, color=\"red\") # coordinate point\n",
    "ax.set_yticks([]) # remove y axis label\n",
    "ax.set_xticks([]) # remove x axis label\n",
    "ax.set_xlabel('x',fontsize=20) # set x label\n",
    "ax.set_ylabel('pdf(x)',fontsize=20,rotation=0) # set y label\n",
    "ax.xaxis.set_label_coords(0.61, -0.02) # x label coordinate\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5) # y label coordinate\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Since ``norm.pdf`` returns a PDF value, we can use this function to plot the normal distribution function. We graph a PDF of the normal distribution using ``scipy``, ``numpy`` and ``matplotlib``. We use the domain of $âˆ’4 < ð‘¥ < 4$ the range of $0 < ð‘“(ð‘¥) < 0.45$, the default values $\\mu = 0$ and $\\sigma = 1.$ ``plot(x-values, y-values)`` produces the graph."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x= np.arange(-4,4,0.001)\n",
    "ax.set_title('N(0,$1^2$)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.plot(x, norm.pdf(x))\n",
    "ax.set_ylim(0,0.45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "A normal curve is smooth bell-shaped. It is symmetrical about the $x=\\mu$, and has a maximum point at $x=\\mu$.\n",
    "\n",
    "## Normal distribution PDF with different standard deviations\n",
    "\n",
    "Let's plot probability distribution functions of a normal distribution where the mean has different standard deviations.\n",
    "\n",
    "``scipy.norm.pdf`` has keywords, ``loc`` and ``scale``. The location ``loc`` keyword specifies the mean and the scale ``scale`` keyword specifies the standard deviation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-10,10,100)\n",
    "stdvs = [1.0, 2.0, 3.0, 4.0]\n",
    "\n",
    "for s in stdvs:\n",
    "    ax.plot(x, norm.pdf(x,scale=s), label='stdv=%.1f' % s)\n",
    "    \n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.set_title('Normal Distribution')\n",
    "ax.legend(loc='best', frameon=True)\n",
    "ax.set_ylim(0,0.45)\n",
    "ax.grid(True)"
   ]
  },
  {
   "source": [
    "## Normal distribution PDF with different means\n",
    "\n",
    "Let's plot probability distribution functions of normal distribution where the standard deviation is $0$ and different means."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-10,10,100)\n",
    "means = [0.0, 1.0, 2.0, 5.0]\n",
    "\n",
    "for mean in means:\n",
    "    ax.plot(x, norm.pdf(x,loc=mean), label='mean=%.1f' % mean)\n",
    "    \n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.set_title('Normal Distribution')\n",
    "ax.legend(loc='best', frameon=True)\n",
    "ax.set_ylim(0,0.45)\n",
    "ax.grid(True)"
   ]
  },
  {
   "source": [
    "The mean of the distribution determines the location of the center of the graph. As you can see in the above graph, the shape of the graph does not change by changing the mean, but the graph is translated horizontally.\n",
    "\n",
    "## Using random normal distribution values\n",
    "\n",
    "``norm.rvs`` generates random normal distribution numbers according to the scale which is the standard deviation, the ``loc`` which is the mean and the size. We create a histogram for the generated numbers and add the PDF."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xs = norm.rvs(scale=2,size=1000)\n",
    "x = np.linspace(-10,10,100)\n",
    "p = norm.pdf(x,scale=2)\n",
    "v = np.var(xs)\n",
    "m = np.mean(xs)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(xs, bins=10, alpha=0.5, density=True)\n",
    "ax.plot(x,p, 'r-', lw=2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.set_title(f'mean={m:.2f}, var={v:.2f}')\n",
    "ax.grid(True)"
   ]
  },
  {
   "source": [
    "## Cumulative normal distribution function\n",
    "\n",
    "The cumulative distribution function of a random variable $X$, evaluated at $x$, is the probability that $X$ will take a value less than or equal to $x$. Since the normal distribution is a continuous distribution, the shaded area of the curve represents the probability that $X$ is less or equal than $x$.\n",
    "\n",
    "$$P(X \\leq x)=F(x)=\\int \\limits _{-\\infty}^{x}f(t)dt \\text{, where } x\\in \\mathbb{R}$$\n",
    "\n",
    "Using fill between $(x,\\,y_{1},\\,y_{2} = 0)$ fill up the area between two curves $y_{1}$ and $y_{2}$ which has the default is $0$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# for distribution curve\n",
    "x= np.arange(-4,4,0.001)\n",
    "ax.plot(x, norm.pdf(x))\n",
    "ax.set_title(\"Cumulative normal distribution\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "# for fill_between\n",
    "px=np.arange(-4,1,0.01)\n",
    "ax.set_ylim(0,0.5)\n",
    "ax.fill_between(px,norm.pdf(px),alpha=0.5, color='g')\n",
    "# for text\n",
    "ax.text(-1,0.1,\"cdf(x)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Calculating probability of normal distribution\n",
    "\n",
    "Given the mean of $3$ and the standard deviation of $2$, we can find the probability of $P(X<2)$.\n",
    "\n",
    "$$X \\sim N(3,2^2)$$\n",
    "\n",
    "In ``norm.cdf``, the location ``loc`` keyword specifies the mean and the scale ``scale`` keyword specifies the standard deviation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "lessthan2=norm.cdf(x=2, loc=3, scale=2)\n",
    "print(lessthan2)"
   ]
  },
  {
   "source": [
    "Let's plot a graph."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# for distribution curve\n",
    "x= np.arange(-4,10,0.001)\n",
    "ax.plot(x, norm.pdf(x,loc=3,scale=2))\n",
    "ax.set_title(\"N(3,$2^2$)\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "# for fill_between\n",
    "px=np.arange(-4,2,0.01)\n",
    "ax.set_ylim(0,0.25)\n",
    "ax.fill_between(px,norm.pdf(px,loc=3,scale=2),alpha=0.5, color='g')\n",
    "\n",
    "# for text\n",
    "ax.text(-0.5,0.02,round(lessthan2,2), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Interval between variables\n",
    "\n",
    "To find the probability of an interval between certain variables, you need to subtract cdf from another cdf. Let's find $P(0.5<X<2)$ with a mean of $1$ and a standard deviation of $2$.\n",
    "\n",
    "$$X \\sim N(1,2^2)$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(1, 2).cdf(2) - norm(1,2).cdf(0.5)"
   ]
  },
  {
   "source": [
    "Here is the graph.\n",
    "\n",
    "$$X \\sim N(1,2^2),  P(0.5<X<2)$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# for distribution curve\n",
    "x= np.arange(-6,8,0.001)\n",
    "ax.plot(x, norm.pdf(x,loc=1,scale=2))\n",
    "ax.set_title(\"N(1,$2^2$)\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "px=np.arange(0.5,2,0.01)\n",
    "ax.set_ylim(0,0.25)\n",
    "ax.fill_between(px,norm.pdf(px,loc=1,scale=2),alpha=0.5, color='g')\n",
    "\n",
    "pro=norm(1, 2).cdf(2) - norm(1,2).cdf(0.5)\n",
    "ax.text(0.2,0.02,round(pro,2), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "To find the probability of $P(X>4)$, we can use ``sf`` which is called the survival function and it returns ``1-cdf``. For example, ``norm.sf(x=4, loc=3, scale=2)`` returns the probability which is greater than $x=4,P(X>4)$ when $\\mu=4$, $\\sigma=2$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "gr4sf=norm.sf(x=4, loc=3, scale=2)\n",
    "gr4sf"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Let's plot a graph."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x= np.arange(-4,10,0.001)\n",
    "ax.plot(x, norm.pdf(x,loc=3,scale=2))\n",
    "ax.set_title(\"N(3,$2^2$)\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "px=np.arange(4,10,0.01)\n",
    "ax.set_ylim(0,0.25)\n",
    "ax.fill_between(px,norm.pdf(px,loc=3,scale=2),alpha=0.5, color='g')\n",
    "\n",
    "ax.text(4.5,0.02,\"sf(x) %.2f\" %(gr4sf), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "The above graph is the same as $1âˆ’P(X<4)$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr4=norm.cdf(x=4, loc=3, scale=2)\n",
    "gr14=1-gr4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x= np.arange(-4,10,0.001)\n",
    "ax.plot(x, norm.pdf(x,loc=3,scale=2))\n",
    "ax.set_title(\"N(3,$2^2$)\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "px=np.arange(4,10,0.01)\n",
    "ax.set_ylim(0,0.25)\n",
    "ax.fill_between(px,norm.pdf(px,loc=3,scale=2),alpha=0.5, color='g')\n",
    "px1=np.arange(-4,4,0.01)\n",
    "ax.fill_between(px1,norm.pdf(px1,loc=3,scale=2),alpha=0.5, color='r')\n",
    "ax.text(4.5,0.02,round(gr14,2), fontsize=20)\n",
    "ax.text(1,0.02,round(gr4,2), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Finding quantiles\n",
    "\n",
    "$k$ in $P(Xâ‰¤k)=0.95$ is known as quantile, in this case the $95%$ quantile.\n",
    "\n",
    "## Percent point function\n",
    "\n",
    "``ppf`` is the inverse of cdf and it is called Percent point function. Given the mean of $1$ and the standard deviation of $3$, we can find the quantile a in $P(X<a)=0.506$ by using ``ppf``.\n",
    "\n",
    "$$X \\sim N(1,3^2)$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf(q=0.506, loc=1, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x= np.arange(-10,10,0.001)\n",
    "ax.plot(x, norm.pdf(x,loc=1,scale=3))\n",
    "ax.set_title(\"N(1,$3^2$)\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "xpoint=norm.ppf(q=0.506, loc=1, scale=3)\n",
    "px=np.arange(-10,xpoint,0.01)\n",
    "ax.set_ylim(0,0.15)\n",
    "ax.fill_between(px,norm.pdf(px,loc=1,scale=3),alpha=0.5, color='g')\n",
    "\n",
    "ax.text(.8,0.02,\"x= %.2f\" %xpoint, fontsize=20)\n",
    "ax.text(-5,0.05,\"P(X)=0.506\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Inverse survival function\n",
    "\n",
    "With the same mean and standard deviation, we can find the quantile $b$ in $P(X>b)=0.198$ using the inverse survival function ``isf``. This is the same as using ``ppf`` with $q=(1âˆ’0.198)$.\n",
    "\n",
    "$$X \\sim N(1,3^2)$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.isf(q=0.198, loc=1, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf(q=(1-0.198), loc=1, scale=3)"
   ]
  },
  {
   "source": [
    "## Interval around the mean\n",
    "\n",
    "``norm.interval`` returns endpoints of the range that contains alpha percent of the distribution. For example, with a mean of $0$ and a standard deviation of $1$ to find $95\\%$ of the probability, ``norm.interval`` returns $x$ values around the mean, in this case, $\\mu=0$.\n",
    "\n",
    "$$X \\sim N(0,1^2)$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = norm.interval(alpha=0.95, loc=0, scale=1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x= np.arange(-4,4,0.001)\n",
    "ax.plot(x, norm.pdf(x))\n",
    "ax.set_title(\"Interval\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('pdf(x)')\n",
    "ax.grid(True)\n",
    "\n",
    "px=np.arange(a,b,0.01)\n",
    "ax.set_ylim(0,0.5)\n",
    "ax.fill_between(px,norm.pdf(px),alpha=0.5, color='g')\n",
    "\n",
    "ax.text(-0.5,0.1,\"0.95\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Multivariate Normal Distribution\n",
    "\n",
    "The multivariate normal distribution is often used to describe any set of correlated real-valued random variables.\n",
    "\n",
    "We use ``multivariate_normal`` which requires the array of mean and covariance matrix. To make it simple,we use a diagonal matrix which all off-diagonal elements are zero."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "x,y = np.meshgrid(np.linspace(-10,10,100),np.linspace(-10,10,100))\n",
    "pos = np.dstack((x,y))\n",
    "mean = np.array([1, 2])\n",
    "cov  = np.array([[3,0],[0,15]])\n",
    "rv = multivariate_normal(mean,cov)\n",
    "z = rv.pdf(pos)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111,aspect='equal')\n",
    "ax.contourf(x,y,z)\n",
    "ax.set_xlim(-10,10)\n",
    "ax.set_ylim(-10,10)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('pdf')"
   ]
  },
  {
   "source": [
    "We can create a 3D graph using the matplotlib's <a href=\"https://matplotlib.org/stable/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.html\">mpl_toolkits.mplot3d.Axes3D</a>. We also use <a href=\"https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html#freezing-a-distribution\">Scipy frozen RV object</a>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create grid and multivariate normal\n",
    "x = np.linspace(-10,10,500)\n",
    "y = np.linspace(-10,10,500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X \n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "# Create a frozen RV object\n",
    "mean = np.array([1, 2])\n",
    "cov  = np.array([[3,0],[0,15]])\n",
    "rv = multivariate_normal(mean,cov)\n",
    "\n",
    "# Make a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Y, rv.pdf(pos),cmap='viridis',linewidth=0)\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Standard normal distribution\n",
    "\n",
    "When $\\mu=0$ and $variance=1$, it is called the standard normal distribution. The above probability function is simplified to:\n",
    "\n",
    "$$\\Phi(x)=\\frac{1}{\\sqrt{2\\pi}}e^{\\frac{-x^2}{2}}$$\n",
    "$$Z \\sim N(0,1)$$\n",
    "\n",
    "All normal curves can be related to the standard normal distribution.\n",
    "\n",
    "## Standardized normal variable\n",
    "\n",
    "To standardize a random variable $Xâˆ¼N(\\mu,\\sigma^2)$ into the standardized normal variable $Zâˆ¼N(0,1)$ we use the transformation:\n",
    "\n",
    "$$Z=\\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "The standardized value $Z$ tells how many standard deviations below or above the mean the original value is.\n",
    "\n",
    "## Finding the standard normal value\n",
    "For example, to find the standardized value for $x=1$ when a mean of $2$ and a standard deviation of $3$.\n",
    "\n",
    "$$\\text{For }X \\sim N(2,3^2)$$\n",
    "$$Z=\\frac{1-2}{3}$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=(1-2)/3\n",
    "z"
   ]
  },
  {
   "source": [
    "We can use ``norm.cdf`` to find the probability and use ``norm.ppf`` with $\\mu=0$,$\\sigma=1$ to find the standardized value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(1, loc=2, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf(q=norm.cdf(1, loc=2, scale=3))"
   ]
  },
  {
   "source": [
    "## Conclusion\n",
    "<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\">scipy.stats.norm</a> gives us parameters such as loc and scale to specifies the standard deviation. It also has a variety of methods and we explored ``rvs``, ``cdf``, ``sf``, ``ppf``, ``interval``, and ``isf`` in this article.\n",
    "\n",
    "<a href=\"https://matplotlib.org/index.html\">Matplotlib</a> gives us easy but extensive tools to change very minute details of a figure including 3D.\n",
    "\n",
    "## References\n",
    "\n",
    "* https://qiita.com/supersaiakujin/items/71540d1ecd60ced65add\n",
    "* http://kaisk.hatenadiary.com/entry/2015/02/17/192955\n",
    "* https://stackoverflow.com/questions/38698277/plot-normal-distribution-in-3d"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " - Exercici 2 :\n",
    "Crea una funciÃ³ que et generi un quadrat NxN de nombres aleatoris entre el 0 i el 100."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_matrix(func):\n",
    "    # added arguments inside the wrapper, if function takes\n",
    "    # any arguments, can be added like this.\n",
    "    def wrapper(*args, **kwargs):\n",
    "        #for arg in args:\n",
    "        #    print(\"Next dimemsion through *args is :\", arg)\n",
    "\n",
    "        #for arg in kwargs:\n",
    "        #    print(\"Next dimemsion through *kwargs is :\", kwargs)\n",
    "\n",
    "        if len(kwargs) == 0:\n",
    "            kwargs = {'range': 100, 'decimals': 1}\n",
    "        elif len(kwargs) == 1:\n",
    "            key = str(*kwargs.keys())\n",
    "            #print(kwargs[key])\n",
    "            #print(kwargs.get(key))\n",
    "            if key == 'range':\n",
    "                kwargs['decimals'] = 1\n",
    "            elif key == 'decimals':\n",
    "                kwargs['range'] = 100\n",
    "\n",
    "        # getting the returned value\n",
    "        array = func(*args) #array = func(*args, **kwargs)\n",
    "\n",
    "        # Multiply x range to obtain de value between the range [0-100]\n",
    "        array *= kwargs['range']\n",
    "        array = np.round(array, kwargs['decimals'])\n",
    "        print('NumPy Array: \\n{arr}\\n'.format(arr = array))\n",
    "        # returning the value to the original frame\n",
    "        return array\n",
    "    return wrapper\n",
    "\n",
    "@random_matrix\n",
    "def create_array(*args, **kwargs):\n",
    "    # Generates a random vector with a given length\n",
    "    return np.random.rand(*args, **kwargs)\n",
    "\n",
    "shape = (10, 10)\n",
    "#create_array(*shape, range = 100, decimals = 1)\n",
    "create_array(*shape, decimals = 1)\n",
    "#create_array(10, 10, range = 100)"
   ]
  },
  {
   "source": [
    "- Exercici 3 :\n",
    "Crea una funciÃ³ que donada una taula de dues dimensions, et calculi els totals per fila i els totals per columna."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rows_and_columns(func):\n",
    "    def wrapper(arr, *args, **kwargs):\n",
    "        print('Sum of the matrix by Columns and Rows :\\n')\n",
    "        #sense = ['Column', 'Row']\n",
    "\n",
    "        # getting the returned value\n",
    "        for i in range(0, arr.ndim):\n",
    "            array = func(arr, axis = i)\n",
    "            #print(Sum of the matrix by {dim} : \\n{arr}\\n'.format(dim = sense[i], arr = array))\n",
    "\n",
    "        # returning to the original frame\n",
    "        return\n",
    "    return wrapper\n",
    "\n",
    "#@sum_rows_and_columns\n",
    "def sum_by_axis(arr, *args, **kwargs):\n",
    "    # for sum, axis is the first keyword, so we may omit it, specifying only its value\n",
    "    # ndarray.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)\n",
    "    if len(args) != 0:\n",
    "        arg1 = int(*args)\n",
    "        if arg1 == 0:\n",
    "             sense = 'by Columns'\n",
    "        elif arg1 == 1:\n",
    "             sense = 'by Rows'\n",
    "        else:\n",
    "             print('Error Dim out of range')\n",
    "    elif len(kwargs) != 0 :\n",
    "        key = str(*kwargs.keys())\n",
    "        if key == 'axis':\n",
    "            if kwargs[key] == 0:\n",
    "                sense = 'by Columns'\n",
    "            elif kwargs[key] == 1:\n",
    "                sense = 'by Rows'\n",
    "            else:\n",
    "                print('Error Dim out of range')\n",
    "    else:\n",
    "        sense = '(Total)'\n",
    "    array = arr.sum(*args, **kwargs)\n",
    "    array = np.around(array, decimals = 2)\n",
    "    print('Sum of the matrix {dim} : \\n{arr}\\n'.format(dim = sense, arr = array))\n",
    "    return array\n",
    "\n",
    "# Create a 2D array with random elements\n",
    "arr = create_array(2, 2)\n",
    "\n",
    "# Calculate the sum of the matrix by columns (0) or by rows (1) \n",
    "list0 = sum_by_axis(arr)                # Columns\n",
    "list1 = sum_by_axis(arr, 0)             # Columns\n",
    "list2 = sum_by_axis(arr, 1)             # Rows\n",
    "list1 = sum_by_axis(arr, axis = 0)      # Columns\n",
    "list2 = sum_by_axis(arr, axis = 1)      # Rows\n",
    "\n",
    "# Sum of matrices by columns and rows\n",
    "summatory = sum_rows_and_columns(sum_by_axis)\n",
    "summatory(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import time\n",
    "\n",
    "# A decorator that prints the function execution duration useful for bench-marking.\n",
    "# decorator to calculate duration taken by any function.\n",
    "def benchmark(func):\n",
    "      \n",
    "    # added arguments inside the wrapper,\n",
    "    # if function takes any arguments,\n",
    "    # can be added like this.\n",
    "    def wrapper(*args, **kwargs):\n",
    "  \n",
    "        # storing time before function execution\n",
    "        begin = time.time()\n",
    "        #begin = time.thread_time()\n",
    "        \n",
    "        # getting the returned value\n",
    "        returned_value = func(*args, **kwargs)\n",
    "  \n",
    "        # storing time after function execution\n",
    "        end = time.time()\n",
    "        #end = time.thread_time()\n",
    "        print(\"Total time taken in : \", func.__name__, end - begin)\n",
    "        # returning the value to the original frame\n",
    "        return returned_value\n",
    "    return wrapper\n",
    "\n",
    "_list = [*range(10 ** 6)]\n",
    "#print(_list)\n",
    "\n",
    "@benchmark\n",
    "def foo():\n",
    "  list(reversed(_list))\n",
    "\n",
    "@benchmark\n",
    "def bar():\n",
    "  _list.reverse()\n",
    "\n",
    "print(foo())\n",
    "print(bar())\n",
    "# foo 0.03308224678039551\n",
    "# bar 0.000997781753540039"
   ]
  },
  {
   "source": [
    "- Exercici 4 :\n",
    "Implementa manualment una funciÃ³ que calculi el coeficient de correlaciÃ³. Informaâ€™t-en sobre els seus usos i interpretaciÃ³."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def average(x):\n",
    "    assert len(x) > 0\n",
    "    return float(sum(x)) / len(x)\n",
    "\n",
    "@benchmark\n",
    "def pearson_func1(x, y):\n",
    "    # Assume len(x) == len(y)\n",
    "    assert len(x) == len(y)\n",
    "    n = len(x)\n",
    "    assert n > 0\n",
    "    avg_x = average(x)\n",
    "    avg_y = average(y)\n",
    "    diffprod = 0\n",
    "    xdiff2   = 0\n",
    "    ydiff2   = 0\n",
    "    for idx in range(n):\n",
    "        xdiff     = x[idx] - avg_x\n",
    "        ydiff     = y[idx] - avg_y\n",
    "        diffprod += xdiff * ydiff\n",
    "        xdiff2   += xdiff * xdiff\n",
    "        ydiff2   += ydiff * ydiff\n",
    "    den = math.sqrt(xdiff2 * ydiff2)\n",
    "    if den == 0:\n",
    "      print('Division by zero')\n",
    "      return\n",
    "    pearson_coef = diffprod / den\n",
    "    print('Pearson correlation coefficient (fun1): {coef}'.format(coef = pearson_coef))\n",
    "    return pearson_coef\n",
    "\n",
    "@benchmark\n",
    "def pearson_func2(x, y):\n",
    "  # Assume len(x) == len(y)\n",
    "  assert len(x) == len(y)\n",
    "  n = len(x)\n",
    "  assert n > 0\n",
    "  sum_x = float(sum(x))\n",
    "  sum_y = float(sum(y))\n",
    "  sum_x_sq = sum(xi * xi for xi in x)\n",
    "  sum_y_sq = sum(yi * yi for yi in y)\n",
    "  psum = sum(xi * yi for xi, yi in zip(x, y))\n",
    "  num = psum - (sum_x * sum_y / n)\n",
    "  den = pow((sum_x_sq - pow(sum_x, 2) / n) * (sum_y_sq - pow(sum_y, 2) / n), 0.5)\n",
    "  if den == 0:\n",
    "    print('Division by zero')\n",
    "    return\n",
    "  pearson_coef = num / den\n",
    "  print('Pearson correlation coefficient (fun2): {coef}'.format(coef = pearson_coef))\n",
    "  return pearson_coef"
   ]
  },
  {
   "source": [
    "## What is Correlation?\n",
    "\n",
    "Variables within a dataset can be related for lots of reasons.\n",
    "\n",
    "For example:\n",
    "\n",
    "* One variable could cause or depend on the values of another variable.\n",
    "* One variable could be lightly associated with another variable.\n",
    "* Two variables could depend on a third unknown variable.\n",
    "\n",
    "It can be useful in data analysis and modeling to better understand the relationships between variables. The statistical relationship between two variables is referred to as their correlation.\n",
    "\n",
    "A correlation could be positive, meaning both variables move in the same direction, or negative, meaning that when one variableâ€™s value increases, the other variablesâ€™ values decrease. Correlation can also be neutral or zero, meaning that the variables are unrelated.\n",
    "\n",
    "* Positive Correlation: both variables change in the same direction.\n",
    "* Neutral Correlation: No relationship in the change of the variables.\n",
    "* Negative Correlation: variables change in opposite directions.\n",
    "\n",
    "The performance of some algorithms can deteriorate if two or more variables are tightly related, called multicollinearity. An example is linear regression, where one of the offending correlated variables should be removed in order to improve the skill of the model.\n",
    "\n",
    "We may also be interested in the correlation between input variables with the output variable in order provide insight into which variables may or may not be relevant as input for developing a model.\n",
    "\n",
    "The structure of the relationship may be known, e.g. it may be linear, or we may have no idea whether a relationship exists between two variables or what structure it may take. Depending what is known about the relationship and the distribution of the variables, different correlation scores can be calculated.\n",
    "\n",
    "In this tutorial, we will look at one score for variables that have a Gaussian distribution and a linear relationship and another that does not assume a distribution and will report on any monotonic (increasing or decreasing) relationship.\n",
    "\n",
    "## Test Dataset\n",
    "\n",
    "Before we look at correlation methods, letâ€™s define a dataset we can use to test the methods.\n",
    "\n",
    "We will generate 1,000 samples of two two variables with a strong positive correlation. The first variable will be random numbers drawn from a Gaussian distribution with a mean of 100 and a standard deviation of 20. The second variable will be values from the first variable with Gaussian noise added with a mean of a 50 and a standard deviation of 10.\n",
    "\n",
    "We will use the ``randn()`` function to generate random Gaussian values with a mean of $0$ and a standard deviation of $1$, then multiply the results by our own standard deviation and add the mean to shift the values into the preferred range.\n",
    "\n",
    "The pseudorandom number generator is seeded to ensure that we get the same sample of numbers each time the code is run."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate related variables :\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot\n",
    "from numpy import cov\n",
    "from scipy import stats\n",
    "\n",
    "# Seed random number generator\n",
    "seed(1)\n",
    "# Prepare data\n",
    "data1 = 20 * randn(1000) + 100\n",
    "data2 = data1 + (10 * randn(1000) + 50)"
   ]
  },
  {
   "source": [
    "Running the example first prints the mean and standard deviation for each variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Summarize\n",
    "print('data1: mean = %.3f stdv = %.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean = %.3f stdv = %.3f' % (mean(data2), std(data2)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "A scatter plot of the two variables is created. Because we contrived the dataset, we know there is a relationship between the two variables. This is clear when we review the generated scatter plot where we can see an increasing trend.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "pyplot.scatter(data1, data2)\n",
    "pyplot.title('Scatter plot of the test correlation dataset')\n",
    "pyplot.show()"
   ]
  },
  {
   "source": [
    "Before we look at calculating some correlation scores, we must first look at an important statistical building block, called covariance.\n",
    "\n",
    "## Covariance\n",
    "\n",
    "Variables can be related by a linear relationship. This is a relationship that is consistently additive across the two data samples.\n",
    "\n",
    "This relationship can be summarized between two variables, called the covariance. It is calculated as the average of the product between the values from each sample, where the values haven been centered (had their mean subtracted).\n",
    "\n",
    "The calculation of the sample covariance is as follows :\n",
    "\n",
    "$$\\text{cov(X, Y)} = S_{xy} = \\frac{\\sum_{i=1}^{n} \\left(x_i - \\bar{x}\\right)\\left(y_i - \\bar{y}\\right)}{n-1}$$\n",
    "\n",
    "The use of the mean in the calculation suggests the need for each data sample to have a Gaussian or Gaussian-like distribution.\n",
    "\n",
    "The sign of the covariance can be interpreted as whether the two variables change in the same direction (positive) or change in different directions (negative). The magnitude of the covariance is not easily interpreted. A covariance value of zero indicates that both variables are completely independent.\n",
    "\n",
    "The ``cov()`` **NumPy** function can be used to calculate a covariance matrix between two or more variables.\n",
    "\n",
    "$$\\text{covariance} = \\text{cov}(data_{1}, data_{2})$$\n",
    "\n",
    "The diagonal of the matrix contains the covariance between each variable and itself. The other values in the matrix represent the covariance between the two variables; in this case, the remaining two values are the same given that we are calculating the covariance for only two variables.\n",
    "\n",
    "We can calculate the covariance matrix for the two variables in our test problem.\n",
    "\n",
    "The calculate example is listed below :\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate covariance matrix\n",
    "covariance = cov(data1, data2)\n",
    "print(covariance)"
   ]
  },
  {
   "source": [
    "The covariance and covariance matrix are used widely within statistics and multivariate analysis to characterize the relationships between two or more variables.\n",
    "\n",
    "Running the example calculates and prints the covariance matrix.\n",
    "\n",
    "Because the dataset was contrived with each variable drawn from a Gaussian distribution and the variables linearly correlated, covariance is a reasonable method for describing the relationship.\n",
    "\n",
    "The covariance between the two variables is $389.75$. We can see that it is positive, suggesting the variables change in the same direction as we expect.\n",
    "\n",
    "A problem with covariance as a statistical tool alone is that it is challenging to interpret. This leads us to the Pearsonâ€™s correlation coefficient next.\n",
    "\n",
    "## Pearsonâ€™s Correlation\n",
    "\n",
    "The Pearson correlation coefficient (named for Karl Pearson) can be used to summarize the strength of the linear relationship between two data samples.\n",
    "\n",
    "The Pearsonâ€™s correlation coefficient is calculated as the covariance of the two variables divided by the product of the standard deviation of each data sample. It is the normalization of the covariance between the two variables to give an interpretable score.\n",
    "\n",
    "$$\\text{Pearson's correlation coefficient}\\,r = \\frac{\\text{covariance}(X, Y)}{(\\text{stdv(X)} * \\text{stdv(Y)})}$$\n",
    "\n",
    "$$= \\frac{\\sum_{i=1}^{n} (x_i - \\overline{x}) (y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\overline{x})^2(y_i - \\overline{y})^2}}$$\n",
    "\n",
    "He use of mean and standard deviation in the calculation suggests the need for the two data samples to have a Gaussian or Gaussian-like distribution.\n",
    "\n",
    "The result of the calculation, the correlation coefficient can be interpreted to understand the relationship.\n",
    "\n",
    "The coefficient returns a value between -1 and 1 that represents the limits of correlation from a full negative correlation to a full positive correlation. A value of $0$ means no correlation. The value must be interpreted, where often a value below $-0.5$ or above $0.5$ indicates a notable correlation, and values below those values suggests a less notable correlation.\n",
    "\n",
    "The ``pearsonr()`` **SciPy** function can be used to calculate the Pearsonâ€™s correlation coefficient between two data samples with the same length.\n",
    "\n",
    "We can calculate the correlation between the two variables in our test problem.\n",
    "\n",
    "The calculate example is listed below:\n",
    "___\n",
    "\n",
    "### scipy.stats.pearsonr(x, y)\n",
    "\n",
    "Pearson correlation coefficient and p-value for testing non-correlation.\n",
    "\n",
    "The Pearson correlation coefficient [1] measures the linear relationship between two datasets. The calculation of the p-value relies on the assumption that each dataset is normally distributed. (See Kowalski [3] for a discussion of the effects of non-normality of the input on the distribution of the correlation coefficient.) Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact linear relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
    "\n",
    "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Pearson correlation at least as extreme as the one computed from these datasets.\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|Parameters:|Input x :  | (N,) array_like |\n",
    "|           |Input y :  | (N,) array_like |\n",
    "|Returns:\t|           |(Pearsonâ€™s correlation coefficient, 2-tailed p-value)|\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Pearson's correlation\n",
    "corr = stats.pearsonr(data1, data2)\n",
    "print('Pearsons correlation: {0}'.format(corr))"
   ]
  },
  {
   "source": [
    "Running the example calculates and prints the Pearsonâ€™s correlation coefficient.\n",
    "\n",
    "We can see that the two variables are positively correlated and that the correlation is $0.8$. This suggests a high level of correlation, e.g. a value above $0.5$ and close to $1.0$.\n",
    "\n",
    "$$\\text{Pearsons correlation : } 0.888$$\n",
    "\n",
    "The Pearsonâ€™s correlation coefficient can be used to evaluate the relationship between more than two variables.\n",
    "\n",
    "This can be done by calculating a matrix of the relationships between each pair of variables in the dataset. The result is a symmetric matrix called a correlation matrix with a value of $1.0$ along the diagonal as each column always perfectly correlates with itself.\n",
    "\n",
    "## Spearmanâ€™s Correlation\n",
    "\n",
    "Two variables may be related by a nonlinear relationship, such that the relationship is stronger or weaker across the distribution of the variables.\n",
    "\n",
    "Further, the two variables being considered may have a non-Gaussian distribution.\n",
    "\n",
    "In this case, the Spearmanâ€™s correlation coefficient (named for Charles Spearman) can be used to summarize the strength between the two data samples. This test of relationship can also be used if there is a linear relationship between the variables, but will have slightly less power (e.g. may result in lower coefficient scores).\n",
    "\n",
    "As with the Pearson correlation coefficient, the scores are between $-1$ and $1$ for perfectly negatively correlated variables and perfectly positively correlated respectively.\n",
    "\n",
    "Instead of calculating the coefficient using covariance and standard deviations on the samples themselves, these statistics are calculated from the relative rank of values on each sample. This is a common approach used in non-parametric statistics, e.g. statistical methods where we do not assume a distribution of the data such as Gaussian.\n",
    "\n",
    "$$\\text{Spearman's correlation coefficient} = \\frac{\\text{covariance}(rank(X), rank(Y))}{(\\text{stdv}(rank(X)) * \\text{stdv}(rank(Y)))}$$\n",
    "\n",
    "$$\\rho = 1 - {\\frac {6 \\sum d_i^2}{n(n^2 - 1)}}$$\n",
    "\n",
    "where :\n",
    "\n",
    "d = the pairwise distances of the ranks of the variables $x_{i}$ and $y_{i}$.\n",
    "\n",
    "n = the number of samples.\n",
    "\n",
    "\n",
    "A linear relationship between the variables is not assumed, although a monotonic relationship is assumed. This is a mathematical name for an increasing or decreasing relationship between the two variables.\n",
    "\n",
    "If you are unsure of the distribution and possible relationships between two variables, Spearman correlation coefficient is a good tool to use.\n",
    "\n",
    "The ``spearmanr()`` **SciPy** function can be used to calculate the Spearmanâ€™s correlation coefficient between two data samples with the same length.\n",
    "\n",
    "We can calculate the correlation between the two variables in our test problem.\n",
    "\n",
    "The calculate example is listed below :\n",
    "___\n",
    "\n",
    "### scipy.stats.spearmanr(a, b=None, axis=0, nan_policy='propagate')\n",
    "\n",
    "Calculate a Spearman correlation coefficient with associated p-value.\n",
    "\n",
    "The Spearman rank-order correlation coefficient is a nonparametric measure of the monotonicity of the relationship between two datasets. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact monotonic relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
    "\n",
    "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Spearman correlation at least as extreme as the one computed from these datasets. The p-values are not entirely reliable but are probably reasonable for datasets larger than 500 or so.\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "| Parameters: |  a, b  |   1D or 2D array_like, b is optional  |\n",
    "| | |One or two 1-D or 2-D arrays containing multiple variables and observations. When these are 1-D, each represents a vector of observations of a single variable. For the behavior in the 2-D case, see under axis, below. Both arrays need to have the same length in the axis dimension.|\n",
    "| | axis    |   int or None, optional   |\n",
    "| |         |   If axis=0 (default), then each column represents a variable, with observations in the rows. If axis=1, the relationship is transposed: each row represents a variable, while the columns contain observations. If axis=None, then both arrays will be raveled.|\n",
    "| | nan_policy   |{``propagate``, ``raise``, ``omit``}, optional    |\n",
    "| |              |Defines how to handle when input contains nan. The following options are available (default is ``propagate``):\n",
    "| |              | * ``propagate``: returns nan\n",
    "| |              | * ``raise``: throws an error\n",
    "| |              | * ``omit``: performs the calculations ignoring nan values\n",
    "| Returns : | correlation   | float or ndarray (2-D square) |\n",
    "| |         | Spearman correlation matrix or correlation coefficient (if only 2 variables are given as parameters. Correlation matrix is square with length equal to total number of variables (columns or rows) in a and b combined.   |\n",
    "| | pvaluefloat | The two-sided p-value for a hypothesis test whose null hypothesis is that two sets of data are uncorrelated, has same dimension as rho.|\n",
    "\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate spearman's correlation\n",
    "corr = stats.spearmanr(data1, data2)\n",
    "print('Spearmans correlation: ', corr)"
   ]
  },
  {
   "source": [
    "As with the Pearsonâ€™s correlation coefficient, the coefficient can be calculated pair-wise for each variable in a dataset to give a correlation matrix for review."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined function 1\n",
    "pearson_func1(data1, data2)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# User defined function 2\n",
    "pearson_func2(data1, data2)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# storing time before function execution\n",
    "begin = time.time()\n",
    "# Scipy built-in function library\n",
    "p_coef = scipy.stats.pearsonr(data1, data2)\n",
    "# storing time after function execution\n",
    "end = time.time()\n",
    "print('Pearson correlation coefficient (fun3): {coef}'.format(coef = p_coef))\n",
    "print(\"Total time taken in :  pearson_Scipy\", end - begin)"
   ]
  }
 ]
}